{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#setup"
      ],
      "metadata": {
        "id": "dhESWm8WdoFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5-eZiXFx75p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "from torch import nn\n",
        "from torchvision.transforms import v2\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find torchinfo ... instaling...\")\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "try:\n",
        "  from helper_function import data_setup, get_data, helper_fuction, engine\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "  !git clone https://github.com/ir252525/helper_functions\n",
        "  !mv helper_functions/helper_function . # get the helper_functions.py script\n",
        "  !rm -rf helper_functions\n",
        "  from helper_function import data_setup, get_data, helper_fuction, engine\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "device = 'cuda'if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = Path(\"dataset\")\n",
        "image_path = data_path / \"images\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory allredy exisets !!\")\n",
        "else:\n",
        "  print(f\"Did not find {image_path} directory, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "url = \"https://storage.googleapis.com/kaggle-data-sets/7871951/12477751/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250720%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250720T105235Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2b2c2f830c6d70e87fc7788bdc4a41fa924b37bf7123a584ffdf43fb9603491d5128af5652b737416acd80e08dcc06a2d4db17a6cce0241cab8e21ac38c8a299c1a9df4aca2d9677b25cdab059c9a0adfe5487ba4debfff72e3605ce9af94c0ea17403bc0d34edd31c0046e7d0552dd53aef2fe8bda61ce4a256f59d94a2eb6f976a4e6f35e853758cfe2b68b330da065cd822881a0f7440ef692d1bc17b9922314466b52c6f2a0f71e6ab307df15c0dc316b2aaec354e408117b837c773b641771238c1e56e18ba41ae8bebeb816bc5a375aebd985637008f9690be71cc1576798d2a4fd5fd34909b19a34466b7abc999d5b25d625eb52e1604544ee88853cf\"\n",
        "\n",
        "with open(data_path / \"images.zip\" , \"wb\")as f:\n",
        "  requests = requests.get(url=url)\n",
        "  print(\"Downloading datasets ...\")\n",
        "  f.write(requests.content)\n",
        "\n",
        "with zipfile.ZipFile(data_path / \"images.zip\", \"r\")as zip_ref:\n",
        "  print(\"Unziping datasets files ...\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "Y5Wak2zQzOBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "YrV22ppK2aOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "4ZhdFhJJ5xIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Set parameters\n",
        "original_dir = Path(\"dataset/images/Garbage_Dataset_Classification/images\")\n",
        "train_dir = Path(\"dataset/images/train\")\n",
        "test_dir = Path(\"dataset/images/test\")\n",
        "split_ratio = 0.8\n",
        "\n",
        "# Create train/test directories\n",
        "for class_dir in original_dir.iterdir():\n",
        "    if class_dir.is_dir():\n",
        "        # Create class folders in train and test dirs\n",
        "        (train_dir / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
        "        (test_dir / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Get image files\n",
        "        image_files = list(class_dir.glob(\"*.jpg\"))\n",
        "        random.shuffle(image_files)\n",
        "        split_index = int(len(image_files) * split_ratio)\n",
        "\n",
        "        # Move files\n",
        "        for img_path in image_files[:split_index]:\n",
        "            shutil.copy(img_path, train_dir / class_dir.name / img_path.name)\n",
        "        for img_path in image_files[split_index:]:\n",
        "            shutil.copy(img_path, test_dir / class_dir.name / img_path.name)\n"
      ],
      "metadata": {
        "id": "WyRGgG_xNgdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "test_dir, train_dir"
      ],
      "metadata": {
        "id": "ISx8NkM0QYUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "image_path_list = list(image_path.glob(\"*/*/*/*.jpg\"))\n",
        "\n",
        "\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "img_as_arrey = np.asarray(img)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_as_arrey)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_arrey.shape} -> [height, width, color_channels]\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "NpDx4nen6J_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_transforms = v2.Compose([\n",
        "    v2.Resize(size=(224, 224)),\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True)\n",
        "])\n",
        "simple_transforms"
      ],
      "metadata": {
        "id": "QHYwiQX_6ssj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_transform = v2.Compose([\n",
        "    v2.Resize(size=(224, 224)),\n",
        "    v2.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "    v2.Resize(size=(224, 224)),\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "test_transform,train_transform"
      ],
      "metadata": {
        "id": "hJxmQW3lGfVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_function.helper_fuction import plot_transformed_images\n",
        "\n",
        "plot_transformed_images(image_paths= image_path_list, transform= train_transform)"
      ],
      "metadata": {
        "id": "q6I_j-IIKBCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "train_data = datasets.ImageFolder(root = train_dir,\n",
        "                                  transform= train_transform,\n",
        "                                  target_transform= None)\n",
        "test_data = datasets.ImageFolder(root = test_dir,\n",
        "                                 transform= test_transform)\n",
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
      ],
      "metadata": {
        "id": "T03untrsLBBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_dict = train_data.class_to_idx\n",
        "print(f\"class names : {class_names}\\n class idx : {class_dict}\\n lenth of train data : {len(train_data)}\\n lenth of test data : {len(test_data)}\")"
      ],
      "metadata": {
        "id": "VHWZay0AM5U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader = DataLoader(dataset= train_data,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              shuffle = True,\n",
        "                              pin_memory=True,\n",
        "                              num_workers=NUM_WORKERS)\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             shuffle= False,\n",
        "                             pin_memory=True,\n",
        "                             num_workers=NUM_WORKERS)\n",
        "\n",
        "print(f\" train dataloader : {train_dataloader}\\n test dataloader : {test_dataloader}\\n lenth of train dataloader : {len(train_dataloader)}\\n lenth of test dataloader : {len(test_dataloader)}\")"
      ],
      "metadata": {
        "id": "i5beJIbwM_N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_batch , label_batch = next(iter(train_dataloader))\n",
        "\n",
        "img_singel , label_singel = img_batch[0].unsqueeze(dim= 0), label_batch[0]\n",
        "\n",
        "img_singel.shape, label_singel"
      ],
      "metadata": {
        "id": "AR4zjuGxTrX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model 1\n",
        "## mnasnet1_3"
      ],
      "metadata": {
        "id": "IjSKfRtkdhMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_01 = torchvision.models.mnasnet1_3(weights=\"DEFAULT\").to(device)\n",
        "model_01"
      ],
      "metadata": {
        "id": "koW5DPFm8-lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in model_01.parameters():\n",
        "  params.requires_grad = False\n",
        "\n",
        "for param in model_01.layers[14].parameters() :\n",
        "  param.requires_grad = True\n",
        "\n",
        "for param in model_01.layers[15].parameters() :\n",
        "  param.requires_grad = True\n",
        "\n",
        "\n",
        "model_01.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5, inplace = True),\n",
        "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
        ")\n",
        "\n",
        "summary(model_01,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "J4YUxyuTGtkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "epochs = 10\n",
        "lr = 0.001\n",
        "weight_decay = 1e-5\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimaizer = torch.optim.Adam(params = model_01.parameters(),\n",
        "                              lr = lr,\n",
        "                              weight_decay = weight_decay)\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "reasults_model_01 = engine.train(model = model_01,\n",
        "                                 train_dataloader = train_dataloader,\n",
        "                                 test_dataloader = test_dataloader,\n",
        "                                 optimizer = optimaizer,\n",
        "                                 loss_fn = loss_fn,\n",
        "                                 epochs = epochs,\n",
        "                                 device = device)\n",
        "end_time = timer()\n",
        "\n",
        "total_time_model_01 = end_time - start_time\n",
        "print(f\"train total time on {device}: {(total_time_model_01/60):.1f} Minutes\")"
      ],
      "metadata": {
        "id": "dWcHTqRpHxHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "helper_fuction.plot_loss_curves(reasults_model_01)"
      ],
      "metadata": {
        "id": "TqJA17f7DicJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_function.helper_fuction import pred_and_plot_image\n",
        "import random\n",
        "\n",
        "bum_images_to_plot = 3\n",
        "test_image_data_path = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "random_test_image_path = random.sample(population =test_image_data_path,\n",
        "                                       k = bum_images_to_plot)\n",
        "\n",
        "\n",
        "for image_path in random_test_image_path :\n",
        "  pred_and_plot_image(model = model_01,\n",
        "                      image_path = image_path,\n",
        "                      class_names = class_names,\n",
        "                      device = device)"
      ],
      "metadata": {
        "id": "P73HX_vQINVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_function.utils import save_model\n",
        "\n",
        "save_model(model = model_01,\n",
        "           model_name = \"01_mnasnet1_3_pretrained_model.pth\",\n",
        "           target_dir = \"models\")"
      ],
      "metadata": {
        "id": "IhL5A3y4LWgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_mnasnet_model_size = Path(\"models/01_mnasnet1_3_pretrained_model.pth\").stat().st_size // (1024*1024)\n",
        "print(f\"pretrained mnasnet model size : {pretrained_mnasnet_model_size} MB\")"
      ],
      "metadata": {
        "id": "lsH6dHejPjAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnasnet_total_params = sum(torch.numel(param) for param in model_01.parameters())\n",
        "mnasnet_total_params"
      ],
      "metadata": {
        "id": "Yc1U06xYQMia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnasnet_stats = {\"test_loss\": reasults_model_01[\"test_loss\"][-1],\n",
        "                 \"test_acc\": reasults_model_01[\"test_acc\"][-1],\n",
        "                 \"epochs\" : epochs,\n",
        "                 \"taining_time\": total_time_model_01,\n",
        "                 \"number_of_parameters\": mnasnet_total_params,\n",
        "                 \"model_size (MB)\": pretrained_mnasnet_model_size}\n",
        "mnasnet_stats"
      ],
      "metadata": {
        "id": "47GgrqL6T1yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model 2\n",
        "##efficientnet_b1"
      ],
      "metadata": {
        "id": "PU-2rdfxcj8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_02 = torchvision.models.efficientnet_b1(weights=\"IMAGENET1K_V2\").to(device)\n",
        "model_02"
      ],
      "metadata": {
        "id": "0mcEC5ngUu1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in model_02.parameters():\n",
        "  params.requires_grad = False\n",
        "\n",
        "for param in model_02.features[8].parameters() :\n",
        "  param.requires_grad = True\n",
        "\n",
        "model_02.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace = True),\n",
        "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
        ")\n",
        "\n",
        "summary(model_02,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "Yn-EPSK1bxFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "epochs = 10\n",
        "lr = 0.001\n",
        "weight_decay = 1e-5\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimaizer = torch.optim.Adam(params = model_02.parameters(),\n",
        "                              lr = lr,\n",
        "                              weight_decay = weight_decay)\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "reasults_model_02 = engine.train(model = model_02,\n",
        "                                 train_dataloader = train_dataloader,\n",
        "                                 test_dataloader = test_dataloader,\n",
        "                                 optimizer = optimaizer,\n",
        "                                 loss_fn = loss_fn,\n",
        "                                 epochs = epochs,\n",
        "                                 device = device)\n",
        "end_time = timer()\n",
        "\n",
        "total_time_model_02 = end_time - start_time\n",
        "print(f\"train total time on {device}: {(total_time_model_02/60):.1f} Minutes\")"
      ],
      "metadata": {
        "id": "JcDCrvU3c8ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "helper_fuction.plot_loss_curves(reasults_model_02)"
      ],
      "metadata": {
        "id": "QKo2W2bsdRd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_function.helper_fuction import pred_and_plot_image\n",
        "import random\n",
        "\n",
        "bum_images_to_plot = 3\n",
        "test_image_data_path = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "random_test_image_path = random.sample(population =test_image_data_path,\n",
        "                                       k = bum_images_to_plot)\n",
        "\n",
        "\n",
        "for image_path in random_test_image_path :\n",
        "  pred_and_plot_image(model = model_02,\n",
        "                      image_path = image_path,\n",
        "                      class_names = class_names,\n",
        "                      device = device)"
      ],
      "metadata": {
        "id": "_ZwwG2W2eGFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_function.utils import save_model\n",
        "\n",
        "save_model(model = model_02,\n",
        "           model_name = \"02_efficientnet_b1_pretrained_model.pth\",\n",
        "           target_dir = \"models\")"
      ],
      "metadata": {
        "id": "w9MvcgFreNLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_efficientnet_b1_model_size = Path(\"models/02_efficientnet_b1_pretrained_model.pth\").stat().st_size // (1024*1024)\n",
        "print(f\"pretrained efficientnet_b1 model size : {pretrained_efficientnet_b1_model_size} MB\")"
      ],
      "metadata": {
        "id": "WQEJy-luehlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_b1_total_params = sum(torch.numel(param) for param in model_02.parameters())\n",
        "efficientnet_b1_total_params"
      ],
      "metadata": {
        "id": "IZk0XByTezHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_b1_stats = {\"test_loss\": reasults_model_02[\"test_loss\"][-1],\n",
        "                         \"test_acc\": reasults_model_02[\"test_acc\"][-1],\n",
        "                         \"epochs\" : epochs,\n",
        "                         \"taining_time\": total_time_model_02,\n",
        "                         \"number_of_parameters\": efficientnet_b1_total_params,\n",
        "                         \"model_size (MB)\": pretrained_efficientnet_b1_model_size}\n",
        "efficientnet_b1_stats"
      ],
      "metadata": {
        "id": "PCEs1t6MfBZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 3\n",
        "testing model across all test dataset and timeing them + compering models so we can choose the best model"
      ],
      "metadata": {
        "id": "_OhRS_Gmit4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get all test data paths\n",
        "print(f\"[INFO] Finding all filepaths ending with '.jpg' in directory: {test_dir}\")\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_data_paths[:5]"
      ],
      "metadata": {
        "id": "iNT1yEFOitEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_function.helper_fuction import pred_and_store\n",
        "\n",
        "mnasnet_test_pred_dict = pred_and_store(paths= test_data_paths,\n",
        "                                        model = model_01,\n",
        "                                        transform = simple_transforms,\n",
        "                                        class_names = class_names,\n",
        "                                        device = \"cpu\")\n",
        "mnasnet_test_pred_dict[:2]"
      ],
      "metadata": {
        "id": "y13PfKX6jbn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_b1_test_pred_dict = pred_and_store(paths= test_data_paths,\n",
        "                                                model = model_02,\n",
        "                                                transform = simple_transforms,\n",
        "                                                class_names = class_names,\n",
        "                                                device = \"cpu\")\n",
        "efficientnet_b1_test_pred_dict[:2]"
      ],
      "metadata": {
        "id": "BuziqFZukdl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "mnasnet_test_pred_pd = pd.DataFrame(mnasnet_test_pred_dict)\n",
        "efficientnet_b1_test_pred_pd = pd.DataFrame(efficientnet_b1_test_pred_dict)\n",
        "\n",
        "print(f\"mnasnet data : {mnasnet_test_pred_pd.head()}\\n efficientnet_b1 data{efficientnet_b1_test_pred_pd.head()}\")"
      ],
      "metadata": {
        "id": "hkJHqlJ6kpIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"mnasnet correct predict : {mnasnet_test_pred_pd.correct.value_counts()}\\n\")\n",
        "print(f\"efficientnet_b1 correct predict : {efficientnet_b1_test_pred_pd.correct.value_counts()}\")"
      ],
      "metadata": {
        "id": "ofRJCbBRlIjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnasnet_average_time_per_pred = round(mnasnet_test_pred_pd.time_for_pred.mean(), 4)\n",
        "efficientnet_b1_average_time_per_pred = round(efficientnet_b1_test_pred_pd.time_for_pred.mean(), 4)\n",
        "print(f\"mnasnet average time per prediction: {mnasnet_average_time_per_pred} seconds\\n\")\n",
        "print(f\"EffNetB1 average time per prediction: {efficientnet_b1_average_time_per_pred} seconds\")"
      ],
      "metadata": {
        "id": "G6fUjKRCmgoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnasnet_stats[\"time_per_pred_cpu\"] = mnasnet_average_time_per_pred\n",
        "efficientnet_b1_stats[\"time_per_pred_cpu\"] = efficientnet_b1_average_time_per_pred"
      ],
      "metadata": {
        "id": "OMQty8yLm_ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([mnasnet_stats, efficientnet_b1_stats])\n",
        "\n",
        "df[\"model\"] = [\"mnasnet1_3\", \"efficientnet_b1\"]\n",
        "\n",
        "df[\"test_acc\"] = round(df[\"test_acc\"] * 100, 2)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "Yw4jSHzonay4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#creating a app out of the best model:"
      ],
      "metadata": {
        "id": "0hLRJqayoWHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "garbage_Classification = Path(\"demo/garbage_Classification/\")\n",
        "\n",
        "garbage_Classification.mkdir(parents=True, exist_ok= True)\n",
        "\n",
        "(garbage_Classification / \"exampels\").mkdir(parents=True, exist_ok= True)"
      ],
      "metadata": {
        "id": "2izANtCJn4aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://vistapointe.net/images/bottles-10.jpg\n",
        "!mv bottles-10.jpg demo/garbage_Classification/exampels/\n",
        "\n",
        "!mv models/02_efficientnet_b1_pretrained_model.pth demo/garbage_Classification"
      ],
      "metadata": {
        "id": "CWXIt6rhprk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "garbage_Classification_class_names = garbage_Classification / \"class_names.txt\"\n",
        "\n",
        "with open(garbage_Classification_class_names, \"w\")as f:\n",
        "  print(f\"writhing class names to {garbage_Classification_class_names} file\")\n",
        "  f.write(\"\\n\".join(class_names))"
      ],
      "metadata": {
        "id": "Cj9ZwJpdrb2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(garbage_Classification_class_names, \"r\") as f:\n",
        "  garbage_Classification_class_names_loaded = [garbage.strip() for garbage in f.readlines()]\n",
        "\n",
        "garbage_Classification_class_names_loaded"
      ],
      "metadata": {
        "id": "4KdVY6vfskVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo/garbage_Classification/model.py\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "\n",
        "def creat_effnetb1(num_classes: int= 6,\n",
        "                   seed : int= 42):\n",
        "  \"\"\"Creates an EfficientNetB1 feature extractor model and transforms.\n",
        "\n",
        "  Args:\n",
        "      num_classes (int, optional): number of classes in the classifier head.\n",
        "          Defaults to 3.\n",
        "      seed (int, optional): random seed value. Defaults to 42.\n",
        "\n",
        "  Returns:\n",
        "      model (torch.nn.Module): EffNetB1 feature extractor model.\n",
        "      transforms (torchvision.transforms): test image transforms.\n",
        "  \"\"\"\n",
        "  transform = v2.Compose([\n",
        "      v2.Resize(size=(224, 224)),\n",
        "      v2.ToImage(),\n",
        "      v2.ToDtype(torch.float32, scale=True),\n",
        "      v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "      ])\n",
        "\n",
        "  model = torchvision.models.efficientnet_b1(weights=\"IMAGENET1K_V2\")\n",
        "\n",
        "  for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "  for param in model.features[8].parameters() :\n",
        "    param.requires_grad = True\n",
        "\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  model.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.2, inplace = True),\n",
        "      nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n",
        "      )\n",
        "  return model, transform"
      ],
      "metadata": {
        "id": "iTKeQBQetT7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo/garbage_Classification/app.py\n",
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from model import creat_effnetb1\n",
        "from timeit import default_timer as timer\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "with open(garbage_Classification_class_names, \"r\") as f:\n",
        "  class_names = [garbage.strip() for garbage in f.readlines()]\n",
        "\n",
        "effnetb1 , transform = creat_effnetb1(num_classes = len(class_names),\n",
        "                                      seed = 42)\n",
        "\n",
        "effnetb1.load_state_dict(\n",
        "    torch.load(\n",
        "        f = \"02_efficientnet_b1_pretrained_model.pth\",\n",
        "        map_location= torch.device(\"cpu\")\n",
        "    )\n",
        ")\n",
        "\n",
        "def prdict(image) -> Tuple[Dict, float]:\n",
        "\n",
        "  start_time = timer()\n",
        "\n",
        "  image = transform(image).unsqueeze(dime = 1)\n",
        "\n",
        "  effnetb1.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    pred_prob = torch.softmax(effnetb1(image), dime= 1)\n",
        "\n",
        "  pred_labels_and_probs = {class_names[i]: float(pred_prob[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "  pred_time = round(timer() - start_time, 5)\n",
        "\n",
        "  return pred_labels_and_probs, pred_time\n",
        "\n",
        "\n",
        "title = \"Garbage Classification\"\n",
        "description = \"An EfficientNetB1 feature extractor computer vision model to classify images of garbage into [6 different classes].\"\n",
        "article = \"Created by Esmail khosravi(ir25) in 2025/7/22.\"\n",
        "\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=prdict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=3, label=\"Predictions\"),\n",
        "        gr.Number(label=\"Prediction time (s)\"),\n",
        "    ],\n",
        "    examples=example_list,\n",
        "    title=title,\n",
        "    description=description,\n",
        "    article=article,\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "piE3pDD1zaXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo/garbage_Classification/requirements.txt\n",
        "\n",
        "torch == 2.6.0\n",
        "torchvision == 0.21.0\n",
        "gradio==5.37.0"
      ],
      "metadata": {
        "id": "AKWxuJq2x5tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd demo/garbage_Classification && zip -r ../garbage_Classification.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\"\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"demo/garbage_Classification.zip\")\n",
        "except:\n",
        "    print(\"Not running in Google Colab, can't use google.colab.files.download()\")"
      ],
      "metadata": {
        "id": "sTbDqQqPzf7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWDPqS0nz66z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}